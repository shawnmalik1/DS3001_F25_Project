%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Milestone 2: Pre-Analysis Plan}

\begin{document}

\twocolumn[
\icmltitle{Milestone 2: \\
            Pre-Analysis Plan}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Shawn Malik}{equal,yyy}
\icmlauthor{Huyen Huynh}{equal,yyy}
\icmlauthor{Wenwan Xu}{equal,yyy}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{University of Virginia, Charlottesville, Virginia, USA}

% \icmlcorrespondingauthor{Firstname1 Lastname1}{first1.last1@xxx.edu}
% \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

%\begin{abstract}

%\end{abstract}

\section{Data}
\label{sec:data}

\subsection*{Sources and Scope}
All data, reports, and code will be at the link below:

\url{https://github.com/shawnmalik1/DS3001_F25_Project}

This project seeks to answer the question: Which performance metrics best predict NBA player salaries?

This project combines two season-level player files:
\begin{itemize}
    \item \textbf{Player Performance} (\texttt{player\_stats.csv}): per-player statistics of NBA players for season 2024--25 from Basketball-Reference, including counting metrics (e.g., \texttt{G}, \texttt{MP}), efficiency and usage rates (e.g., \texttt{TS\%}, \texttt{3PAr}, \texttt{FTr}, \texttt{USG\%}), play-type rate stats (e.g., \texttt{AST\%}, \texttt{TRB\%}, \texttt{STL\%}, \texttt{BLK\%}, \texttt{TOV\%}), and all-in metrics (e.g., \texttt{PER}, \texttt{WS}, \texttt{WS/48}, \texttt{OBPM}, \texttt{DBPM}, \texttt{BPM}, \texttt{VORP}), plus demographics/role (\texttt{Age}, \texttt{Pos}, \texttt{Team}).
    
    \item \textbf{Player Salary} (\texttt{player\_salaries.csv}): per-player base-salary information from Basketball-Reference by future season (e.g., 2025--26, 2026--27, \ldots) and a total guaranteed money.
\end{itemize}

Both files are sourced from Basketball-Reference, which keeps naming and IDs consistent across statistics and contracts.
The modeling target is \emph{next season's} base salary (2025--26), and predictors are taken from the immediately preceding season's on-court performance. This aligns the temporal sequence of ``performance $\rightarrow$ pay.''

\subsection*{Unit of Analysis and Coverage}
Basketball-Reference reports one row per team stint and, for traded players, sometimes an aggregated multi-team line (e.g. ``2TM / 3TM''). To keep things simple and consistent, we define one row per player-season by selecting the \textbf{single team stint with the most minutes} (\texttt{MP}) for each player. This yields a representative stat line while avoiding double-counting and extra aggregation steps if a player played for a team and then got traded to another team in the same season. We will use the team that had the highest stint for that player.

After this filtering, we merge the stats and salary files and retain only players with both a prior-season stat line and a 2025--26 base salary. Not all players will meet both conditions, so some players will drop because they lack a next-season salary (unsigned, two-way/10-day conversions) or did not log meaningful minutes in the prior season.

\subsection*{Identifiers and Merge Strategy}
When available, we use the Basketball-Reference player ID (e.g., \texttt{lillada01}) to create a common key \texttt{bbref\_id} and perform an \textbf{inner join}. If an ID is missing for a small number of rows, we fall back to a name-based merge after light name cleaning (standardizing suffixes such as ``Jr.''/``III'').  The team variable that appears in both datasets (\texttt{Team} in \texttt{player\_stats.csv} and \texttt{Tm} in \texttt{player\_salaries.csv}) also helps us to double-check the merging process after we rename them to be the same. 
Using IDs where possible minimizes mismatches from suffixes, abbreviations, and nicknames.

\subsection*{Key Variables}
\textbf{Base salary (2025--26) ($Y$)}: parsed from currency strings into numeric values (USD). The distribution is strongly right-skewed: many players have salaries around the league minimum, and a long tail up to super max-level salaries ($\sim\$60$M).

\paragraph{Candidate predictors (\(X\))}
\begin{itemize}
    \item \textbf{Availability \& playing time:} \texttt{G} (Games), \texttt{MP} (Minutes Played). Minutes both signal value and stabilize stats.
    \item \textbf{Efficiency \& usage:} \texttt{TS\%} (True Shooting Percentage), \texttt{3PAr} (3-Point Attempt Rate), \texttt{FTr} (Free Throw Attempt Rate), \texttt{USG\%} (Usage Percentage).
    \item \textbf{Role/rate indicators:} \texttt{AST\%} (Assist Percentage), \texttt{TRB\%} (Total Rebound Percentage, which could be specified through \texttt{ORB\%}, Offensive Rebound Percentage, and \texttt{DRB\%}, Defensive Rebound Percentage), \texttt{STL\%} (Steal Percentage), \texttt{BLK\%} (Block Percentage), \texttt{TOV\%} (Turnover Percentage).
    \item \textbf{Overall metrics:} \texttt{PER} (Player Efficiency Rating), \texttt{WS} (Win Shares), \texttt{WS/48} (Win Shares Per 48 Minutes), \texttt{OBPM} (Offensive Box Plus/Minus), \texttt{DBPM} (Defensive Box Plus/Minus), \texttt{BPM} (Box Plus/Minus), \texttt{VORP} (Value over Replacement Player).
    \item \textbf{Demographics/role:} \texttt{Age}, \texttt{Pos} (Position). Team indicators are available if market/team effects are modeled.
\end{itemize}

\subsection*{Reading, Cleaning, and Preparation}
\begin{enumerate}
    \item  \textbf{Read data from a single source.} Sourcing from Basketball-Reference~\cite{bbref_contracts,bbref_advanced_stats_2025}, which is the single database for both of our data sets keeps identifiers consistent. Reading in as \texttt{csv} files allows for straightforward integration and ensures compatibility with subsequent data processing in Python. 
    \item \textbf{Consolidate multi-team seasons.} Retain the consolidated ``xTM'' line; otherwise, keep the highest-\texttt{MP} stint. This yields exactly one prior-season stat line per player and prevents double-counting.
    \item \textbf{Parse money fields.} Strip ``\$'' and commas, coerce to numeric. Use 2025--26 base salary as the target; guaranteed totals span multiple years/options and are not modeled directly.
    \item \textbf{Handle missing data.} Drop rows missing the target salary or essential stats (e.g., \texttt{MP}, \texttt{Age}). Leave rarely used or mostly-empty fields (e.g., awards) out of the model.
    \item \textbf{Basic feature set.} Use straightforward predictors: \texttt{MP}, \texttt{G}, \texttt{TS\%}, \texttt{USG\%}, \texttt{AST\%}, \texttt{TRB\%}, \texttt{STL\%}, \texttt{BLK\%}, \texttt{TOV\%}, and one or two overall metrics (e.g., \texttt{BPM}, \texttt{WS}). Include \texttt{Age} and \texttt{Pos}. 

\end{enumerate}

\section{Methods and Results}
\label{sec:Methods and Results}

\subsection*{Method Overview}
Our goal is to predict each player’s base salary for the 2025–26 NBA season using performance metrics from the 2024–25 season. We frame this as a supervised regression problem in which the target variable is salary (a numeric value in USD) and the predictors are player-level statistics such as minutes, efficiency, usage, and composite performance metrics.

We will begin with an exploratory data analysis (EDA) to examine relationships between the predictors and the target. Visualizations—including histograms, scatter plots, and box plots—will help us assess variable distributions, identify potential transformations, and detect outliers or influential observations. We will also conduct a correlation analysis to identify strong linear relationships and consider removing predictors with very weak correlations to salary, while remaining mindful of possible non-linear effects. In addition, we will explore potential interaction terms, as many basketball statistics are intrinsically correlated (e.g., WS and BPM). Investigating these interactions can reveal combined effects among predictors and inform the use of regularization techniques such as Ridge and Lasso regression to handle multicollinearity and reduce overfitting.

Our modeling strategy begins with simple, interpretable approaches before moving to more flexible models. This staged process allows us to build intuition about the data, understand which variables drive salary differences, and minimize the risk of overfitting.

Ultimately, this approach helps us balance predictive accuracy with interpretability. Beyond producing accurate predictions, we aim to understand how different aspects of player performance contribute to contract value. For example, players with strong efficiency metrics or high playmaking impact may command higher salaries even when their raw counting stats (e.g., points or rebounds) are modest. Insights from early models will guide feature selection, transformations, and model refinement in later stages.

\subsection*{Models}

Our analysis aims to identify which player performance metrics most strongly predict NBA salaries while balancing model interpretability and predictive accuracy. To do so, we adopt a staged modeling approach that begins with transparent, interpretable regression methods and progresses toward more flexible machine-learning models capable of capturing nonlinear relationships.

1. \textbf{Linear Regression.}
We begin with a standard linear regression model as a baseline to establish a direct and interpretable relationship between performance metrics and player salary. This model allows us to estimate marginal effects—how much salary is expected to change, on average, with a one-unit increase in metrics such as minutes played, win shares, or true shooting percentage, holding all other variables constant. Although simple, this baseline model provides a clear benchmark and helps us identify issues such as skewness, outliers, or multicollinearity before progressing to more complex modeling approaches.

2. \textbf{Ridge and Lasso Regression.}
Basketball statistics often exhibit high collinearity—for example, overall impact metrics such as \texttt{BPM}, \texttt{VORP}, and \texttt{WS} are strongly correlated. To address this, we employ Ridge and Lasso regression, which introduce regularization penalties to shrink coefficients and reduce variance. Ridge regression (L2 penalty) stabilizes estimates when predictors are correlated, while Lasso regression (L1 penalty) performs variable selection by shrinking some coefficients exactly to zero. By comparing the results of these two methods, we can both improve predictive performance and identify which features are consistently important across models.

3. \textbf{Random Forest.}
To capture nonlinear relationships and higher-order interactions that linear models might overlook, we incorporate a Random Forest regressor. This ensemble approach aggregates multiple decision trees trained on bootstrapped samples of the data, using random feature selection at each split to enhance robustness. Random Forests handle outliers well and can model complex dependencies—such as the interaction between usage rate and efficiency—without explicit specification. Feature importance measures from this model will also be used to complement coefficient-based interpretations from the linear models.

\paragraph{Implementation and Preprocessing.}
All models are implemented in Python using the \texttt{scikit-learn} library. Numeric predictors are standardized to zero mean and unit variance to ensure comparability, and categorical variables (such as player position) are one-hot encoded. Salary, the dependent variable, is log-transformed to reduce right-skewness and stabilize variance, improving model fit. This unified modeling pipeline allows for reproducibility, consistent evaluation, and transparent comparison across modeling approaches.

\subsection*{Model Validation Plan}

We evaluate model performance through a combination of quantitative metrics, visual diagnostics, and cross-validation to ensure that our findings are both accurate and generalizable.

\paragraph{Data Splitting and Cross-Validation.}
The dataset is partitioned into an 80\% training set and a 20\% held-out test set. Within the training data, we perform 5-fold cross-validation to tune hyperparameters—such as the regularization strength ($\alpha$) in Ridge and Lasso regression—based on predictive performance. This approach balances bias and variance, providing a fair assessment of how well each model generalizes to unseen players.

\paragraph{Evaluation Metrics.}
Each model is assessed using three complementary performance metrics:
\begin{itemize}
    \item \textbf{Root Mean Squared Error (RMSE)} – measures the magnitude of prediction errors, penalizing large deviations heavily.
    \item \textbf{Mean Absolute Error (MAE)} – captures the average absolute difference between predicted and actual salaries, providing an interpretable measure of prediction accuracy.
    \item \textbf{$R^2$ (Coefficient of Determination)} – quantifies the proportion of variance in salaries explained by the model.
\end{itemize}
Together, these metrics allow us to balance interpretability and predictive precision across linear and ensemble models.

\paragraph{Model Diagnostics.}
For linear models, we will perform residual diagnostics to verify key assumptions:
\begin{itemize}
    \item \textbf{Linearity and Homoscedasticity:} Residuals versus fitted values plots will help assess whether variance is constant and relationships are approximately linear.
    \item \textbf{Normality:} Q–Q plots of residuals will indicate whether the error terms are normally distributed.
    \item \textbf{Independence:} An autocorrelation function (ACF) plot will ensure residuals are uncorrelated across observations.
\end{itemize}
If strong violations appear, transformations or alternative model structures (e.g., log-salary, interaction terms) will be considered.

\paragraph{Model Comparison and Interpretation.}
After validation, models will be compared on both test-set performance and interpretability. Visual tools such as predicted-versus-actual scatter plots will reveal systematic bias (e.g., underprediction of high earners). Coefficient magnitudes (from linear and regularized models) and feature importance scores (from Random Forest) will be jointly analyzed to identify which performance metrics consistently predict salary. We expect that indicators of playing time (\texttt{MP}), efficiency (\texttt{TS\%}), and overall impact (\texttt{BPM}, \texttt{VORP}, \texttt{WS}) will emerge as the strongest predictors.

Finally, we will reflect on the uncertainty of our assessments—particularly for outlier cases such as rookies or players on unusual contract structures—and discuss how model limitations affect the confidence of our conclusions.

\subsection*{Next Steps}

Once models are trained and validated, we will compare them and interpret which performance metrics best explain or predict player salary. 

We expect that metrics capturing playing time (\texttt{MP}), overall impact (\texttt{WS}, \texttt{BPM}, \texttt{VORP}), and efficiency (\texttt{TS\%}) will emerge as the strongest predictors.









\bibliography{milestone_data}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
